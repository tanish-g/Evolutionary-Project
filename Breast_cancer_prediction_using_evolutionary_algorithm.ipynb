{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "id": "4cMvmA0-2J6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Hh-qw92H0F"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "\n",
        "set_seed(9)\n",
        "# print('*'*10,seed,'*'*10)\n",
        "# Load the dataset from the UCI Machine Learning Repository or your source\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
        "names = ['id_number', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
        "        'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean',\n",
        "        'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se',\n",
        "        'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave_points_se',\n",
        "        'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
        "        'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst',\n",
        "        'concavity_worst', 'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
        "\n",
        "data = pd.read_csv(url, names=names)\n",
        "\n",
        "print(len(data))\n",
        "\n",
        "# Preprocessing\n",
        "# Drop unnecessary columns\n",
        "data.drop(['id_number'], axis=1, inplace=True)\n",
        "# Convert diagnosis (M/B) to binary labels (1/0)\n",
        "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Splitting the data into features and target\n",
        "X = data.drop(['diagnosis'], axis=1)\n",
        "y = data['diagnosis']\n",
        "\n",
        "# Splitting data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "cols = [x for x in range(len(X_train.columns))]\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Genetic Algorithm Feature Selection\n",
        "def evaluate_individual(individual, X, y):\n",
        "    selected_features = [feature for feature, mask in zip(cols, individual) if mask]\n",
        "    if len(selected_features) == 0:\n",
        "        return 0,\n",
        "\n",
        "    clf = SVC(kernel='linear')\n",
        "    print(selected_features)\n",
        "    X_selected = X[:,selected_features]\n",
        "    scores = cross_val_score(clf, X_selected, y, cv=5)\n",
        "    return scores.mean(),\n",
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X_train.columns))\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"evaluate\", evaluate_individual, X=X_train_scaled, y=y_train)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "population = toolbox.population(n=10)\n",
        "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=5, verbose=True)\n",
        "\n",
        "best_individual = tools.selBest(population, k=1)[0]\n",
        "selected_features = [feature for feature, mask in zip(X_train.columns, best_individual) if mask]\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Convert NumPy arrays back to DataFrames after feature selection\n",
        "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
        "X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features)\n",
        "\n",
        "# RFC Model Training\n",
        "model = RandomForestClassifier()\n",
        "param_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [10],\n",
        "    'min_samples_split': [2],\n",
        "    'min_samples_leaf': [1]\n",
        "}\n",
        "scorer = make_scorer(f1_score)\n",
        "grid_search = GridSearchCV(model, param_grid, scoring=scorer, cv=5)\n",
        "grid_search.fit(X_train_selected, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = best_model.predict(X_test_selected)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred))\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='RFC')\n",
        "\n",
        "\n",
        "#SVM\n",
        "\n",
        "svm = SVC()\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1],\n",
        "    'gamma': [0.01],\n",
        "    'kernel': ['linear']\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Get the best parameters and best estimator from GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "best_estimator = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Evaluate the best estimator on the test set\n",
        "y_pred = best_estimator.predict(X_test_selected)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred))\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='SVM')\n",
        "\n",
        "#MLP\n",
        "mlp = MLPClassifier(max_iter=100)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(100,50)],\n",
        "    'activation': ['relu'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.01],\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(mlp, param_grid, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Get the best parameters and best estimator from GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "best_estimator = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Evaluate the best estimator on the test set\n",
        "y_pred = best_estimator.predict(X_test_selected)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred))\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='SVM')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BuQAlisgmgrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cAN8XYv6pydY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data.columns)"
      ],
      "metadata": {
        "id": "LBZHtuf12Qhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(selected_features)"
      ],
      "metadata": {
        "id": "J1g0-k1p4_f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrZq_8Vy5HB7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}